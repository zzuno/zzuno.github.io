---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<!--
{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

My area of interest is LLM and Vision-Text multi-modal models and their industrial application.

Currently looking for industrial utilization of LLM and Vision models. Anyone who wants to discuss about it are always welcomed !

# üî• News

- _2025.08_: &nbsp; Asteromorph has revealed its first technical report. Please stay tuned.üôå
<!-- - _2024.03_: &nbsp; I've got accepted as a Ph.D course from [University of Wisconsin-Madison](https://www.wisc.edu) -->
- _2022.12_: &nbsp;üéâüéâ I became to attend [Google Research](https://research.google/) ExploreCSR
- _2020.01_: &nbsp;üî• I am thrilled to announce that I‚Äôve secured an at [Samsung Electronics](https://www.samsung.com/sec/), C-LAB

# üìù Projects

(\* Equal Contribution)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/spacer_img.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Spacer: Towards Engineered Scientific Inspiration](https://arxiv.org/abs/2508.17661)

Asteromorph

<!-- The 62nd Annual Meeting of the Association for Computational Linguistics (ACL), 2024. -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SNU</div><img src='images/grad_cam_juneau.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Challenges on Vision Language Multi-modal model](papers/multimodal.pdf)

**Juneau Jung**, Jaesuk Byun, Taesup Moon

<!-- The 62nd Annual Meeting of the Association for Computational Linguistics (ACL), 2024. -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RL</div><img src='images/multimodal_bandit.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-modal Contextual Bandit
for Movie Recommendation](papers/movierecomm.pdf)

Eungi Kim\*, **Juneau Jung**\*, Eunyi Lyou\*, Kwangeun Yeo\*

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MLVU</div><img src='images/vpt.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[Consistency Explanation for Vision Transformer](papers/vpt.pdf)

Seokhyeon Jeong, Wonkyun Kim, **Juneau Jung**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DL</div><img src='images/u-autoencoder.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[U-Autoencoder: Robust Defence Breakthrough on Adversarial Attack](papers/U-autoencoder.pdf)

**Juneau Jung**, Geun Hyeong Ham, Woo Seok Song, Seung Chan Moon

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ML</div><img src='images/teacher forcing.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

ConvLSTM based OCR breakthrougs with Teacher Forcing

**Juneau Jung**, Sungroh Yoon

</div>

</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">App</div><img src='images/dopelive_downsample.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

[DopeLive: AI-powered Live Stream Service](https://apps.apple.com/kr/app/dope-live-stream-like-a-star/id6738138578)

</div>

</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2024</div><img src='images/grad_cam_juneau.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1"> -->

<!-- [Exploiting Intrinsic Multilateral Logical Rules for Weakly Supervised Natural Language Video Localization.](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\\ -->

# üéñ Honors and Awards

<!-- - _2024.02_ Summa Cum Laude, Dept. of ECE, Seoul National Univeristy -->

- _2023.02_ Kim Tae-hyung Academic Incentives, Seoul National University.
- _2019.03 - 2023.02_ Outstanding Student Scholarship, Seoul National University.
- _2018.03_ National Scholarship for Science and Technology, [Korea Scholarship Foundation](https://www.kosaf.go.kr/ko/main.do).

# üìñ Educations

<!-- - _2024.09 - (now)_, Ph.D Candidate, University of Wisconsin-Madison, Major: Computer Science -->

- _2018.03 - 2024.02_, B.S Eng, Seoul National University, Major: [Electrical & Computer Engineering](https://ece.snu.ac.kr/en).

# üíº Experiences

- _2020_, SW Engineer Intern, [Samsung C-LAB](https://samsungclab.com)

- _2020 - 2021_, Paramedic & Auxiliary Researcher, [National Fire Agency](https://www.nfa.go.kr/eng/) and [National Fire Research Institute](https://nfire.go.kr/index.do),

- _2023_, BS Research Intern, ExploreCSR [Google Research](https://research.google/)

- _2023_, SW Engineer Intern, [Samsung Electronics](https://www.samsung.com/sec/)

- _2023 - 2024_, Business Development, [Greybox Inc.](https://notifly.tech)

- _2024_, Specialized Instructor, [LG Electronics](https://www.lge.co.kr)

- _2025_, AI Research Engineer(Manager), [Asteromorph](https://asteromorph.com/)
